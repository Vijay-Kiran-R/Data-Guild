from agents.base_agent import BaseAgent
from google.adk.agents import Agent
import os
import pandas as pd
import matplotlib
import uuid
import json
import asyncio
import io
import sys
import traceback
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any

# Force Agg backend to prevent GUI errors on servers
matplotlib.use('Agg') 
import matplotlib.pyplot as plt

# --- Data Models (Pydantic) ---

class CodeGeneration(BaseModel):
    """Step 1: The agent generates analysis code."""
    thought_process: str = Field(..., description="The reasoning behind the analysis strategy.")
    code: str = Field(..., description="Executable Python code that calculates stats and generates plots.")

class AnalysisInsight(BaseModel):
    """Step 2: The agent interprets the executed code's output."""
    key_finding: str = Field(..., description="The headline finding from the data.")
    detailed_interpretation: str = Field(..., description="Statistical interpretation referencing specific numbers from output.")
    visual_pattern: str = Field(..., description="Description of the 'naked eye' shape of the plot.")

class DeepDiveTask(BaseModel):
    """A follow-up task generated by the Lead Analyst."""
    analyst_type: str = Field(..., description="Univariate, Bivariate, or Trend")
    task_name: str = Field(..., description="Short name, e.g., 'Q3_Sales_Drop'")
    instruction: str = Field(..., description="Specific question to answer.")

class DeepDivePlan(BaseModel):
    """The Lead Analyst's decision matrix."""
    is_complete: bool = Field(..., description="Set to TRUE only if we have a complete story. FALSE if new tasks are needed.")
    reasoning: str = Field(..., description="Why we are stopping or continuing.")
    next_tasks: Optional[List[DeepDiveTask]] = Field(None, description="List of tasks if is_complete is FALSE.")

# --- Agents ---

class Analyst(BaseAgent):
    """
    Worker Agent: Performs the Code -> Execute (w/ Retry) -> Insight loop.
    """
    def __init__(self, name, specialty):
        # Expert Prompt: Enforces statistical proof over simple descriptions
        instruction = f"You are a Senior {specialty} Analyst. You verify every claim with code execution and statistical proof."
        super().__init__(name=name, system_instruction=instruction)
        self.specialty = specialty

    async def execute_task(self, file_path, schema, task_instruction, plot_filename):
        """
        Performs the analysis loop with Auto-Fix Retries.
        """
        plot_dir = "static/plots"
        if not os.path.exists(plot_dir): os.makedirs(plot_dir)
        plot_path = os.path.join(plot_dir, plot_filename).replace('\\', '/')

        # --- STEP 1: GENERATE INITIAL CODE ---
        prompt_code = f"""
        TASK: {task_instruction}
        CONTEXT: Dataset: '{file_path}' | Schema: {schema}
        
        INSTRUCTIONS:
        1. Write Python code to load data and CALCULATE statistics.
           - Univariate: Skew, Kurtosis, IQR, Outlier count.
           - Bivariate: Correlation coeff, covariance, p-values.
           - Trend: Growth rate, slope, seasonality.
        2. Generate a professional matplotlib plot.
           - Save plot to: '{plot_path}'
           - Call `plt.close()` at the end to free memory.
           - You MAY use seaborn for Heatmaps and complex statistical plots
        3. Return JSON with 'thought_process' and 'code'.
        """
        
        # Using BaseAgent.generate() to leverage ADK Runner internally
        resp_code = await self.generate(prompt_code)
        code_data = self._parse_json(resp_code, CodeGeneration)
        
        if not code_data:
            return {"error": "Failed to generate initial code."}

        # --- STEP 2: EXECUTE WITH AUTO-FIX RETRY LOOP ---
        # This is the "Hard Work" logic you implemented, preserved and refined.
        execution_output = ""
        success = False
        current_code = code_data.code
        
        for attempt in range(3): # 3 Attempts to fix code
            try:
                # Capture stdout to read stats later
                old_stdout = sys.stdout
                redirected_output = io.StringIO()
                sys.stdout = redirected_output
                
                # Execution Scope
                local_scope = {'pd': pd, 'plt': plt, 'np': __import__('numpy')}
                exec(current_code, local_scope)
                
                sys.stdout = old_stdout
                execution_output = redirected_output.getvalue()
                
                # Validation: Did it produce output or a plot?
                if os.path.exists(plot_path) or len(execution_output.strip()) > 0:
                    success = True
                    break # Success! Exit loop.
                else:
                    raise Exception("Code executed but produced no output and no plot.")
                    
            except Exception as e:
                sys.stdout = sys.__stdout__ # Safety restore
                # print(f"  [Attempt {attempt+1} Failed] Error: {e}") # Optional debug print
                
                # FEEDBACK LOOP: Ask Agent to Fix Code
                fix_prompt = f"""
                Your previous code failed to execute or produced no output.
                
                ERROR: {str(e)}
                
                PREVIOUS CODE:
                {current_code}
                
                TASK: Fix the code errors. Check paths, column names, and libraries.
                OUTPUT: Return JSON with 'thought_process' and 'code' (the fixed version).
                """
                resp_fix = await self.generate(fix_prompt)
                fix_data = self._parse_json(resp_fix, CodeGeneration)
                if fix_data:
                    current_code = fix_data.code
                else:
                    break # Failed to generate fix, stop trying

        if not success:
            return {"error": f"Code execution failed after 3 attempts. Last error: {execution_output}"}

        # --- STEP 3: INTERPRET RESULTS (STATISTICAL INSIGHT) ---
        prompt_insight = f"""
        The code has been executed successfully.
        
        CODE OUTPUT (Statistics):
        {execution_output}
        
        PLOT GENERATED: {plot_path}
        
        TASK: Interpret these specific numbers.
        - Do NOT hallucinate numbers. Use the "CODE OUTPUT" above.
        - Example: If output says "Skew: 2.5", write "Distribution is highly right-skewed (skew=2.5)".
        
        OUTPUT: Return JSON with 'key_finding', 'detailed_interpretation', and 'visual_pattern'.
        """
        
        resp_insight = await self.generate(prompt_insight)
        insight_data = self._parse_json(resp_insight, AnalysisInsight)
        
        if not insight_data:
            return {"error": "Failed to interpret results."}

        return {
            "insight": insight_data.detailed_interpretation,
            "visuals": insight_data.visual_pattern,
            "plot": plot_path,
            "stats": execution_output.strip()
        }

    def _parse_json(self, text, model_class):
        try:
            clean = text.replace("```json", "").replace("```", "").strip()
            return model_class.model_validate_json(clean)
        except:
            return None

class LeadAnalyst(BaseAgent):
    """
    Brain Agent: Reviews findings and orders deep dives.
    """
    def __init__(self):
        instruction = "You are a Lead Data Strategist. You review statistical findings and identify gaps requiring investigation."
        super().__init__(name="LeadAnalyst", system_instruction=instruction)

    async def review_and_plan(self, current_insights, schema, iteration_count):
        # Forced stop to prevent infinite loops
        if iteration_count >= 3:
            return DeepDivePlan(is_complete=True, reasoning="Maximum analysis depth reached.", next_tasks=[])

        # Strict instruction to ensure the 'is_complete' field is correct (Fixes the Pydantic error)
        prompt = f"""
        CURRENT INSIGHTS FOUND:
        {json.dumps(current_insights, indent=2, default=str)}
        
        DATASET SCHEMA: {schema}
        
        DECISION TIME (Iteration {iteration_count}):
        1. Do we have a complete picture?
        2. Are there specific anomalies (spikes, outliers, weird correlations) that need a specific "Deep Dive" plot?
        
        MANDATORY RULE:
        - If iteration_count == 0 (First Review), you MUST generate at least 1 new task. Set "is_complete": false.
        - If you add tasks, "is_complete" MUST be false.
        
        OUTPUT: Valid JSON matching this structure:
        {{
            "is_complete": false,
            "reasoning": "We need to investigate the high outliers in sales.",
            "next_tasks": [
                {{
                    "analyst_type": "Univariate", 
                    "task_name": "Sales_Outlier_Focus", 
                    "instruction": "Filter dataset for Sales > 1000 and analyze the distribution of Product Categories within that segment."
                }}
            ]
        }}
        """
        
        resp = await self.generate(prompt)
        try:
            clean = resp.replace("```json", "").replace("```", "").strip()
            return DeepDivePlan.model_validate_json(clean)
        except Exception as e:
            self.logger.error(f"Planning failed: {e}")
            # Fail-safe: return complete to avoid system crash
            return DeepDivePlan(is_complete=True, reasoning=f"Planning parsing error: {e}", next_tasks=[])

class AnalystSquad:
    """
    Orchestrates the Hybrid Workflow: Parallel Scan + Iterative Deep Dives.
    """
    def __init__(self):
        self.uni_agent = Analyst("UniAgent", "Univariate")
        self.bi_agent = Analyst("BiAgent", "Bivariate")
        self.trend_agent = Analyst("TrendAgent", "Trend")
        self.lead_analyst = LeadAnalyst()
        
        self.analysts_map = {
            "Univariate": self.uni_agent,
            "Bivariate": self.bi_agent,
            "Trend": self.trend_agent
        }

    async def run_parallel_analysis(self, file_path: str, schema: dict):
        print("Starting Expert Hybrid Analysis...")
        abs_file_path = os.path.abspath(file_path).replace('\\', '/')
        
        # Knowledge Graph to store all findings
        knowledge_graph = {
            'dataset_metadata': {"schema": schema, "file_path": abs_file_path},
            'findings': {}
        }

        # --- PHASE 1: STANDARD PARALLEL SCAN (Replaces ParallelAgent with asyncio.gather) ---
        # This ensures your 3 base agents run simultaneously.
        print("\n--- Phase 1: Standard Parallel Scan (Uni/Bi/Trend) ---")
        
        initial_tasks = [
            (self.uni_agent, "Analyze distribution of key numeric columns. Calculate skewness and IQR.", "Univariate_chart.png"),
            (self.bi_agent, "Calculate Pearson correlation matrix for numeric columns.", "Bivariate_chart.png"),
            (self.trend_agent, "Analyze overall time-series trend and calculate slope/growth.", "Trend_chart.png")
        ]
        
        # Run all 3 simultaneously
        results = await asyncio.gather(*[
            agent.execute_task(abs_file_path, schema, task, fname) 
            for agent, task, fname in initial_tasks
        ])
        
        knowledge_graph['findings']['Initial_Scan'] = {
            "Univariate": results[0],
            "Bivariate": results[1],
            "Trend": results[2]
        }

        # --- PHASE 2: ITERATIVE DEEP DIVES (The "Lead Analyst" Layer) ---
        iteration = 0
        while True:
            print(f"\n--- Phase 2 (Iter {iteration+1}): Lead Analyst Review ---")
            
            # Lead Analyst looks at what we found so far
            plan = await self.lead_analyst.review_and_plan(knowledge_graph, schema, iteration)
            
            if plan.is_complete:
                print(f"Lead Analyst Decision: STOP. Reasoning: {plan.reasoning}")
                break
            
            if not plan.next_tasks:
                print("Lead Analyst Decision: STOP (No new tasks generated).")
                break

            print(f"Deep Dive Required. Executing {len(plan.next_tasks)} new tasks...")
            
            dive_coroutines = []
            for task in plan.next_tasks:
                agent = self.analysts_map.get(task.analyst_type, self.uni_agent)
                # Unique filename for every new insight
                fname = f"DeepDive_{iteration}_{task.task_name}_{uuid.uuid4().hex[:4]}.png"
                
                print(f"  -> {task.analyst_type} Agent: {task.task_name}")
                dive_coroutines.append(
                    agent.execute_task(abs_file_path, schema, task.instruction, fname)
                )
            
            # Run deep dives in parallel
            dive_results = await asyncio.gather(*dive_coroutines)
            
            # Store findings
            knowledge_graph['findings'][f'Deep_Dive_Iter_{iteration+1}'] = dive_results
            
            iteration += 1

        print("Expert Analysis Workflow Complete.")
        return knowledge_graph